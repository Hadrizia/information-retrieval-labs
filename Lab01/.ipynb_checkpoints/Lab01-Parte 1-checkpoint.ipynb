{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recuperação da Informação\n",
    "\n",
    "## Lab01 - Parte 1 - Construção de Índice Invertido e Busca Booleana\n",
    "\n",
    "Neste lab, inicialmente será criado um índice invertido. Depois, serão implementados os algoritmos de busca booleana: \n",
    "* 1-termo: usuário passa um termo e o algoritmo retorna os documentos associados;\n",
    "* Busca AND: todos os termos da consulta devem estar presentes na página;\n",
    "* Busca OR: algum dos termos da consulta deve estar presente na página.\n",
    "\n",
    "### 1. Importando bibliotecas e os dados a serem indexados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "np.random.seed(543)\n",
    "\n",
    "dictionary = defaultdict(list)\n",
    "dic_frequency = {}\n",
    "\n",
    "FILE_NAME = 'noticias_estadao.csv'\n",
    "\n",
    "df = pd.read_csv(FILE_NAME)\n",
    "\n",
    "# criação de uma nova coluna para a junção do título da notícia com seu conteúdo\n",
    "df['noticia'] = df.titulo + ' ' + df.conteudo\n",
    "\n",
    "AND = 'and'\n",
    "OR = 'or'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Implementando as funções a serem utilizadas posteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tokens(text, docId):\n",
    "    text = text.lower()\n",
    "    tokens = text.split(' ')\n",
    "    return tokens\n",
    "\n",
    "def create_indexes(tokens, docId):\n",
    "    for word in tokens:\n",
    "        if docId not in dictionary[word]:\n",
    "            dictionary[word].append(docId)\n",
    "            \n",
    "def create_frequency():\n",
    "    for word in dictionary:\n",
    "        dic_frequency[word] = len(dictionary[word])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Gerando tokens e criando índices para os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n"
     ]
    }
   ],
   "source": [
    "for index, row in df.iterrows():\n",
    "    if index%1000 == 0:\n",
    "        print (index)\n",
    "    token = create_tokens(row.noticia, row.idNoticia)\n",
    "    create_indexes(token, row.idNoticia)\n",
    "create_frequency()\n",
    "order_docs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Implementando os algoritmos de busca booleana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _one_term(element):\n",
    "    if element in dictionary:\n",
    "        return list(dictionary[element])\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def _and_search(first_element, second_element):\n",
    "    return list(set(_one_term(second_element)).intersection(set(_one_term(first_element))))\n",
    "\n",
    "def _or_search(first_element, second_element):\n",
    "    return list(set(_one_term(second_element)).union(set(_one_term(first_element))))\n",
    "\n",
    "def search(search):\n",
    "    search = search.lower().split(' ')\n",
    "    if len(search) == 1:\n",
    "        return _one_term(search[0])\n",
    "    else:\n",
    "        first_element= search[0]\n",
    "        operator = search[1]\n",
    "        second_element = search[2]\n",
    "        if operator == AND:\n",
    "            return _and_search(first_element, second_element)\n",
    "        elif operator == OR:\n",
    "            return _or_search(first_element,second_element)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Adicionando algumas validações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(search(\"candidatos\")) == 1395\n",
    "assert len(search(\"debate OR presidencial\")) == 1770\n",
    "assert len(search(\"debate AND presidencial\")) == 201\n",
    "assert len(search(\"presidenciáveis OR corruptos\")) == 164\n",
    "assert len(search(\"presidenciáveis AND corruptos\")) == 0\n",
    "assert len(search(\"Belo OR Horizonte\")) == 331\n",
    "assert len(search(\"Belo AND Horizonte\")) == 242"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frequency(element):\n",
    "    return len(dictionary[element])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5382, 1036, 6694, 1370, 1987, 1952, 4802, 2777, 2763, 2779, 5870, 1770, 1068]\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "# for x in dictionary:\n",
    "#     for y in dictionary[x]:\n",
    "#         dictionary[x][y].sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
