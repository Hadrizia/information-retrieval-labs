{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementando um Sistema de Recomendação de Filmes\n",
    "## Recuperação da Informação\n",
    "\n",
    "*Hadrizia Santos*\n",
    "\n",
    "Nesta atividade será implementado um sistema de recomendação de filmes com base nos dados do site MovieLens, utilizando a biblioteca [surprise](http://surpriselib.com/). Ao final desse lab, deve ser possível, a partir do identificador de um usuário, recomendar 10 filmes para este usuário, além de exibir os 3 usuários mais similares a ele. \n",
    "\n",
    "### 1. Importar as bibliotecas necessárias, os dados a serem utilizados e particioná-los \n",
    "Como dito anteriormente, a biblioteca principal para a construção desse sistema de recomendação é a SurpriseLib. Ela provê inclusive os dados do MovieLens, que contém informações sobre avaliações de filmes pelos usuários do site. Estes dados serão particionados em treino e teste, na proporção 85% e 15%, respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "import io\n",
    "import json\n",
    "\n",
    "from surprise import KNNWithMeans, KNNWithZScore, KNNBasic, KNNBaseline\n",
    "from surprise import Dataset, accuracy\n",
    "from surprise.model_selection import cross_validate, train_test_split\n",
    "from surprise import get_dataset_dir\n",
    "\n",
    "\n",
    "# Load the movielens-100k dataset (download it if needed).\n",
    "data = Dataset.load_builtin('ml-100k')\n",
    "\n",
    "# Spliting data in train (85%) and test (15%)\n",
    "trainset, testset = train_test_split(data, test_size=.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Definindo o treino e treinando o modelo\n",
    "\n",
    "A biblioteca disponibiliza alguns algoritmos de treinamento, como Baseline, SVD, KNN (de várias modalidades), etc. O escolhido foi o **KNNWithMeans**, pois foi o que apresentou menor RMSE no conjunto de teste. Usei **cross-validation** com 10 repetições pois acredito que ajuda bastante no treinamento de um modelo que generalize bem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE of algorithm KNNBaseline on 10 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Fold 6  Fold 7  Fold 8  Fold 9  Fold 10 Mean    Std     \n",
      "RMSE (testset)    0.9104  0.9206  0.9172  0.9218  0.9154  0.9309  0.9036  0.9196  0.9029  0.9184  0.9161  0.0081  \n",
      "MAE (testset)     0.7094  0.7200  0.7178  0.7192  0.7140  0.7253  0.7063  0.7172  0.7075  0.7199  0.7156  0.0059  \n",
      "Fit time          1.35    1.73    2.23    2.40    2.09    1.60    2.20    1.51    1.49    2.18    1.88    0.36    \n",
      "Test time         1.71    2.11    1.91    1.60    2.35    2.03    1.78    2.24    1.72    2.53    2.00    0.29    \n",
      "Estimating biases using als...\n",
      "Computing the pearson_baseline similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNBaseline at 0x7fd9d0856a20>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using KNN with k = 40\n",
    "algo = KNNBaseline(k=25, sim_options={'name': 'pearson_baseline', 'user_based': True})\n",
    "\n",
    "# Run 10-fold cross-validation and print results.\n",
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=10, verbose=True)\n",
    "\n",
    "# Training the model\n",
    "algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Avaliando o modelo\n",
    "\n",
    "Agora é hora de testar o modelo. Para isso, será usado um exemplo cuja nota já existe e comparado com a nota que o modelo preveu. O resultado foi: A nota real da avaliação é 4.0 e o modelo preveu 4.056. Acredito ser uma aproximação boa. Além disso, são exibidos os valores de RMSE nos conjuntos de treino e teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 196        item: 302        r_ui = None   est = 4.17   {'actual_k': 25, 'was_impossible': False}\n",
      "A nota real é igual a 4 e a nota da predição foi 4.174729579514185\n",
      "\n",
      "Conjunto de Treino\n",
      "RMSE: 0.4023\n",
      "\n",
      "Conjunto de Teste\n",
      "RMSE: 0.9147\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9147132215516297"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using an example to evaluate the model accuracy\n",
    "userid = str(196)\n",
    "itemid = str(302)\n",
    "actual_rating = 4\n",
    "\n",
    "pred = algo.predict(userid, itemid)\n",
    "print(pred)\n",
    "print ('A nota real é igual a', actual_rating, 'e a nota da predição foi', pred.est)\n",
    "\n",
    "# evaluating on the trainset\n",
    "print(\"\\nConjunto de Treino\")\n",
    "train_pred = algo.test(trainset.build_testset())\n",
    "accuracy.rmse(train_pred)\n",
    "\n",
    "# evaluating on the testset\n",
    "print(\"\\nConjunto de Teste\")\n",
    "test_pred = algo.test(testset)\n",
    "accuracy.rmse(test_pred, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Recomendando filmes para um usuário e retornando os vizinhos mais próximos\n",
    "\n",
    "Dado um usuário, filtra-se o conjunto de teste para recuperar os filmes que o usuário ainda não viu. A partir de cada filme, o modelo irá prever uma avaliação do usuário e no fim serão retornados os 10 filmes com maior avaliação prevista por ele. Desta lista, extrai-se os nomes dos filmes e depois recupera-se os 3 vizinhos mais próximos, com idade e sexo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the movies that user doesn't watch.\n",
    "def get_unwatched_movies(userId):\n",
    "    not_watched = []\n",
    "    for item in testset:\n",
    "        if item[1][0] != userid:\n",
    "            not_watched.append(item)\n",
    "    return not_watched\n",
    "\n",
    "# convert raw ids into movie names\n",
    "def read_item_names():\n",
    "    file_name = get_dataset_dir() + '/ml-100k/ml-100k/u.item'\n",
    "    rid_to_name = {}\n",
    "    with io.open(file_name, 'r', encoding='ISO-8859-1') as f:\n",
    "        for line in f:\n",
    "            line = line.split('|')\n",
    "            rid_to_name[line[0]] = line[1]\n",
    "\n",
    "    return rid_to_name\n",
    "\n",
    "# convert raw ids into user data\n",
    "def id_to_user():\n",
    "    file_name = get_dataset_dir() + '/ml-100k/ml-100k/u.user'\n",
    "    rid_to_user = {}\n",
    "    with io.open(file_name, 'r', encoding='ISO-8859-1') as f:\n",
    "        for line in f:\n",
    "            line = line.split('|')\n",
    "            rid_to_user[line[0]] = {}\n",
    "            rid_to_user[line[0]]['age'] = line[1]\n",
    "            rid_to_user[line[0]]['sex'] = line[2]\n",
    "    return rid_to_user\n",
    "\n",
    "# Get 10 recommended movies\n",
    "def top_10_recommended_movies(userId):\n",
    "    rid_to_name = read_item_names()\n",
    "    \n",
    "    not_watched = get_unwatched_movies(userId)\n",
    "    \n",
    "    predicted_rating = []\n",
    "    \n",
    "    for item in not_watched:\n",
    "        movie = []\n",
    "        movie.append(item[1])\n",
    "        name = rid_to_name[str(item[1])]\n",
    "        movie.append(name)\n",
    "        predition = algo.predict(userid, item[1])\n",
    "        movie.append(float(predition.est))\n",
    "        \n",
    "        if movie not in predicted_rating:\n",
    "            predicted_rating.append(movie)\n",
    "    return sorted(predicted_rating, key=itemgetter(2), reverse = True)[:10]\n",
    "\n",
    "def get_K_neighbors(userId, n_k = 3):\n",
    "    n = []\n",
    "    id_user = id_to_user()\n",
    "    for item in algo.get_neighbors(userId, k = n_k):\n",
    "        n.append(id_user[str(item)])\n",
    "    return n\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filmes recomendados:\n",
      "[['851', 'Two or Three Things I Know About Her (1966)', 5.0], ['1233', 'Nénette et Boni (1996)', 5.0], ['1347', 'Ballad of Narayama, The (Narayama Bushiko) (1958)', 5.0], ['1643', 'Angel Baby (1995)', 5.0], ['1449', 'Pather Panchali (1955)', 4.992997656161196], ['119', 'Maya Lin: A Strong Clear Vision (1994)', 4.849363887024461], ['1367', 'Faust (1994)', 4.8440863113925525], ['285', 'Secrets & Lies (1996)', 4.8042983877854475], ['1377', 'Hotel de Love (1996)', 4.78828426190351], ['8', 'Babe (1995)', 4.774763541071216]]\n",
      "\n",
      "Vizinhos mais próximos:\n",
      "[{'age': '36', 'sex': 'M'}, {'age': '51', 'sex': 'F'}, {'age': '30', 'sex': 'F'}]\n"
     ]
    }
   ],
   "source": [
    "userId = 196\n",
    "print(\"Filmes recomendados:\")\n",
    "print(top_10_recommended_movies(str(userId)))\n",
    "print(\"\\nVizinhos mais próximos:\")\n",
    "print(get_K_neighbors(userId, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def list_to_json(movies):\n",
    "    l = []\n",
    "    for item in movies:\n",
    "        d = {}\n",
    "        d['movieId'] = item[0]\n",
    "        d['movieName'] = item[1]\n",
    "        d['predRating'] = item[2]\n",
    "        l.append(d)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recommended_json(userId):\n",
    "    d = {}\n",
    "    d['movies'] = list_to_json(top_10_recommended_movies(str(userId)))\n",
    "    d['users'] = get_K_neighbors(userId, 3)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'movies': [{'movieId': '851', 'movieName': 'Two or Three Things I Know About Her (1966)', 'predRating': 5.0}, {'movieId': '1233', 'movieName': 'Nénette et Boni (1996)', 'predRating': 5.0}, {'movieId': '1347', 'movieName': 'Ballad of Narayama, The (Narayama Bushiko) (1958)', 'predRating': 5.0}, {'movieId': '1643', 'movieName': 'Angel Baby (1995)', 'predRating': 5.0}, {'movieId': '1449', 'movieName': 'Pather Panchali (1955)', 'predRating': 4.992997656161196}, {'movieId': '119', 'movieName': 'Maya Lin: A Strong Clear Vision (1994)', 'predRating': 4.849363887024461}, {'movieId': '1367', 'movieName': 'Faust (1994)', 'predRating': 4.8440863113925525}, {'movieId': '285', 'movieName': 'Secrets & Lies (1996)', 'predRating': 4.8042983877854475}, {'movieId': '1377', 'movieName': 'Hotel de Love (1996)', 'predRating': 4.78828426190351}, {'movieId': '8', 'movieName': 'Babe (1995)', 'predRating': 4.774763541071216}], 'users': [{'age': '36', 'sex': 'M'}, {'age': '51', 'sex': 'F'}, {'age': '30', 'sex': 'F'}]}\n"
     ]
    }
   ],
   "source": [
    "print(recommended_json(196))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
