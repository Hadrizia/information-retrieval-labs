{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab2 - Expansão de Consultas\n",
    "### Hadrizia Santos\n",
    "Nesta atividade será exercitada a noção de expansão de consultas. Considerando a coleção de notícias do lab passado, deve-se executar os seguintes passos:\n",
    "\n",
    "1. Escrever uma função que receba uma coleção de documentos e retorne uma matrix de termos-termos contendo as frequências de co-ocorrência de duas palavras consecutivas no texto (bigramas).\n",
    "2. Escrever uma função que receba um certo termo de consulta e a matriz construída no passo 1 acima e retorneas top-3 palavras em ordem decrescente de frequencia.\n",
    "3. Expandir a consulta original com os termos retornados no passo 2 acima.\n",
    "4. Fazer uma busca disjuntiva (OR) considerando a nova consulta.\n",
    "\n",
    "E responder às perguntas:\n",
    "\n",
    "* Quais os termos retornados para a expansão de cada consulta?\n",
    "* Você acha que esses termos são de fato relacionados com a consulta original? Justifique.\n",
    "* Compare os documentos retornados para a consulta original com a consulta expandida. Quais resultados você acha que melhor capturam a necessidade de informação do usuário? Por que?\n",
    "* A expansão de consultas é mais adequada para melhorar o recall ou o precision? Por que?\n",
    "\n",
    "## Importar bibliotecas e os dados necessários\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import nltk\n",
    "from nltk import bigrams   \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import scipy.sparse as sps\n",
    "import math\n",
    "import collections\n",
    "import ast\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "FILE_PATH = '../data/estadao_noticias_eleicao.csv'\n",
    "\n",
    "df = pd.read_csv(FILE_PATH, encoding = 'utf-8')\n",
    "df = df.replace(np.NAN, \"\")\n",
    "\n",
    "# criação de uma nova coluna para a junção do título da notícia com seu conteúdo\n",
    "df['noticia'] = df.titulo + ' ' + df.subTitulo + ' ' + df.conteudo\n",
    "\n",
    "dictionary = collections.defaultdict(list)\n",
    "idf_dict = {}\n",
    "total_docs = len(df.noticia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Construir matrix de ocorrência\n",
    "**Obs:** O código abaixo que constrói a matriz de ocorrência foi copiado do repositório que está disponível em: https://github.com/allansales/information-retrieval/blob/master/Lab%202/coocurrence_matrix.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# O código abaixo está disponivel em: \n",
    "# https://github.com/allansales/information-retrieval/blob/master/Lab%202/coocurrence_matrix.ipynb\n",
    "\n",
    "def co_occurrence_matrix(corpus):\n",
    "    vocab = set(corpus)\n",
    "    vocab = list(vocab)\n",
    "    n = len(vocab)\n",
    "   \n",
    "    vocab_to_index = {word:i for i, word in enumerate(vocab)}\n",
    "    \n",
    "    bi_grams = list(bigrams(corpus))\n",
    "\n",
    "    bigram_freq = nltk.FreqDist(bi_grams).most_common(len(bi_grams))\n",
    "\n",
    "    I=list()\n",
    "    J=list()\n",
    "    V=list()\n",
    "    \n",
    "    for bigram in bigram_freq:\n",
    "        current = bigram[0][1]\n",
    "        previous = bigram[0][0]\n",
    "        count = bigram[1]\n",
    "\n",
    "        I.append(vocab_to_index[previous])\n",
    "        J.append(vocab_to_index[current])\n",
    "        V.append(count)\n",
    "        \n",
    "    co_occurrence_matrix = sparse.coo_matrix((V,(I,J)), shape=(n,n))\n",
    "\n",
    "    return co_occurrence_matrix, vocab_to_index\n",
    "\n",
    "def  generate_tokens_dataframe(noticia):\n",
    "    # Removing punctuation\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens_lists = noticia.apply(lambda text: tokenizer.tokenize(text.lower()))\n",
    "    \n",
    "    # Removing stopwords\n",
    "    stopword_ = stopwords.words('portuguese')\n",
    "    filtered_tokens = tokens_lists.apply(lambda tokens: [token for token in tokens if token not in stopword_])\n",
    "    \n",
    "    tokens = [token for tokens_list in filtered_tokens for token in tokens_list]\n",
    "    return tokens\n",
    "\n",
    "def  generate_tokens_text(text):\n",
    "    # Removing punctuation\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens_lists = tokenizer.tokenize(text.lower())\n",
    "    \n",
    "    # Removing stopwords\n",
    "    stopword_ = stopwords.words('portuguese')\n",
    "    filtered_tokens = [token for token in tokens_lists if token not in stopword_]\n",
    "\n",
    "    return filtered_tokens\n",
    "\n",
    "def consult_frequency(w1, w2):\n",
    "    return(consultable_matrix[vocab[w1],vocab[w2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokens = generate_tokens(df.noticia)\n",
    "matrix, vocab = co_occurrence_matrix(tokens)\n",
    "consultable_matrix = matrix.tocsr()\n",
    "inverted_vocab = {vocab[key]: key for key in vocab}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Retornar as top-3 palavras mais frequentes de acordo com a matriz de ocorrência\n",
    "Escrever uma função que receba uma palavra do dicionário e retorne quais as 3 palavras que ocorrem mais frequentemente com o input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_co_ocurrences(co_matrix, inv_vocab, term, N=3):\n",
    "    # sparse to dense representation\n",
    "    np_array = np.reshape(co_matrix[term].toarray(), -1)\n",
    "    # get indice of N occurences\n",
    "    return list(OrderedDict({inv_vocab[idx]: np_array[idx] for idx in (-np_array).argsort()[:N]}).keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Expandir a consulta original com os termos retornados no passo 2 acima.\n",
    "Escrever uma função que receba a consulta, pega as 3 palavras que aparecem com maior frequência junto com esse termo e retorne uma consulta expandida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_query(terms):\n",
    "    query = []\n",
    "    terms = terms.split(' ')\n",
    "    if len(terms) > 1:\n",
    "            for term in terms:\n",
    "                query.append(term)\n",
    "                query.extend(get_co_ocurrences(consultable_matrix, inverted_vocab, vocab[term], 3))\n",
    "    else:\n",
    "        query.append(terms[0])\n",
    "        query.extend(get_co_ocurrences(consultable_matrix, inverted_vocab, vocab[terms[0]], 3))\n",
    "        \n",
    "    # removing duplicates terms\n",
    "    return \" \".join(str(x) for x in set(query))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fazer uma busca disjuntiva (OR) considerando a nova consulta.\n",
    "Escrever uma função que recebe uma consulta de N termos e retorna uma consula disjuntiva entre os termos. O modelo utilizado será o BM25, que foi implementado na atividade anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_indexes(tokens, docId):\n",
    "    for word in tokens:\n",
    "        if word in dictionary: \n",
    "            if docId in dictionary[word]:\n",
    "                dictionary[word][docId] += 1 \n",
    "            else:\n",
    "                dictionary[word][docId] = 1 \n",
    "        else:\n",
    "            dictionary[word] = {}\n",
    "            dictionary[word][docId] = 1\n",
    "            \n",
    "def create_idf(word):\n",
    "    idf = calculate_idf(word)\n",
    "    idf_dict[word] = idf\n",
    "    \n",
    "def calculate_idf(word):\n",
    "    M = total_docs\n",
    "    k = len(dictionary[word].keys())\n",
    "    idf = math.log((M + 1) / k)\n",
    "    return idf\n",
    "\n",
    "def calculate_bm25(tf, k=5):\n",
    "    return (( k + 1) * tf) / ( tf + k)\n",
    "\n",
    "def bm25(query, k):\n",
    "    query = query.lower().split(' ')\n",
    "    \n",
    "    intersect_dict = {}\n",
    "    if len(query) > 1:\n",
    "        for word in query:   \n",
    "            for docId in dictionary[word]:\n",
    "                if docId in intersect_dict:\n",
    "                    intersect_dict[docId] = intersect_dict[docId] + calculate_bm25(dictionary[word][docId], k) * idf_dict[word]\n",
    "                else:\n",
    "                    intersect_dict[docId] = calculate_bm25(dictionary[word][docId], k) * idf_dict[word]\n",
    "    else:\n",
    "        for docId in dictionary[query[0]]:\n",
    "            intersect_dict[docId] = calculate_bm25(dictionary[query[0]][docId], k) * idf_dict[query[0]]\n",
    "            \n",
    "    rank = [(i, intersect_dict[i]) for i in sorted(intersect_dict, key=intersect_dict.get, reverse=True)]\n",
    "\n",
    "    return [doc[0] for doc in rank[:3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating inverted index, TF and IDF\n",
    "for index, row in df.iterrows():  \n",
    "    tokens = generate_tokens_text(row.noticia)\n",
    "    create_indexes(tokens, row.idNoticia)\n",
    "for word in dictionary:\n",
    "    create_idf(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def or_bm25_search(query):\n",
    "    expanded_query = expand_query(query)\n",
    "    return bm25(expanded_query, k=3)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Respondendo às perguntas\n",
    "### Quais os termos retornados para a expansão de cada consulta?\n",
    "As consultas a serem testadas são as seguintes: 'corrupção', 'segundo turno' e 'empresa petrobrás'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query original: segundo turno\n",
      "Query expandida: mandato é eleição eleições lugar segundo turno\n",
      "Query original: lava jato\n",
      "Query expandida: é deflagrada lava porque lato jato polícia\n",
      "Query original: projeto lei\n",
      "Query expandida: político lei projeto anistia responsabilidade ficha poder\n",
      "Query original: compra voto\n",
      "Query expandida: pasadena votos distrital voto compra dilma refinaria presidente\n",
      "Query original: ministério público\n",
      "Query expandida: é saúde fazenda ministério estadual público federal\n"
     ]
    }
   ],
   "source": [
    "queries = ['segundo turno', 'lava jato', 'projeto lei', 'compra voto', 'ministério público']\n",
    "exp_queries = []\n",
    "for query in queries:\n",
    "    ext_query = expand_query(query)\n",
    "    exp_queries.append(ext_query)\n",
    "    print('Query original: %s' % query)\n",
    "    print('Query expandida: %s' % ext_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Você acha que esses termos são de fato relacionados com a consulta original? Justifique.\n",
    "Acredito que os termos estejam relacionados com a consulta original nas duas últimas consultas, pois quando se fala em segundo turno, é normalmente sobre eleições e todos os termos estão relacionados ao contexto. O mesmo ocorre para petrobrás, onde os demais termos se relacionam com a consulta. Já a primeira consulta expandida me surpreendeu um pouco, pois não esperava que petrobrás aparecesse tanto junto de corrupção. Outra coisa que observei é que o termo '**é**', que deveria ser considerada stopword, pois apareceu em todas as consultas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare os documentos retornados para a consulta original com a consulta expandida. Quais resultados você acha que melhor capturam a necessidade de informação do usuário? Por que?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing csv \n",
    "gabarito = pd.read_csv('../data/gabarito.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A expansão de consultas é mais adequada para melhorar o recall ou o precision? Por que?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the average precision at k.\n",
    "\n",
    "    This function computes the average prescision at k between two lists of\n",
    "    items.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of elements that are to be predicted (order doesn't matter)\n",
    "    predicted : list\n",
    "                A list of predicted elements (order does matter)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The average precision at k over the input lists\n",
    "\n",
    "    \"\"\"\n",
    "    if len(predicted)>k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i,p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "def mapk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the mean average precision at k.\n",
    "\n",
    "    This function computes the mean average prescision at k between two lists\n",
    "    of lists of items.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of lists of elements that are to be predicted \n",
    "             (order doesn't matter in the lists)\n",
    "    predicted : list\n",
    "                A list of lists of predicted elements\n",
    "                (order matters in the lists)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The mean average precision at k over the input lists\n",
    "\n",
    "    \"\"\"\n",
    "    return np.mean([apk(a,p,k) for a,p in zip(actual, predicted)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado MAP de acordo com o gabarito\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'bm25_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-147-31aa88005d20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Resultado MAP de acordo com o gabarito'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Precisão gabarito e BM25: %f \\n\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmapk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_to_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgabarito\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbm25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbm25_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'bm25_results' is not defined"
     ]
    }
   ],
   "source": [
    "def obj_to_list(obj):\n",
    "    matrix = []\n",
    "    for list_obj in obj:\n",
    "        x = ast.literal_eval(list_obj)\n",
    "        matrix.append(x)\n",
    "    return matrix \n",
    "\n",
    "print('Resultado MAP de acordo com o gabarito')\n",
    "print (\"Precisão gabarito e BM25: %f \\n\" % (mapk(obj_to_list(gabarito.bm25), bm25_results, k=5)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
