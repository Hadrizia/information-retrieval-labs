{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recuperação da Informação - 2018.1 -- Lab01, parte 2\n",
    "#### *Hadrizia Santos*\n",
    "  Nessa atividade serão implementadas várias instanciações do modelo vetorial, além de terem suas eficiências comparadas em termos de Mean Average Precision (MAP).\n",
    "  \n",
    "## 1. Construindo índice invertido\n",
    "### 1.1. Importar bibliotecas e dados\n",
    "  O primeiro passo é importar as bibliotecas que serão utilizadas e os documentos que serão indexados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/hadrizia/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import collections\n",
    "import operator\n",
    "import nltk\n",
    "import ast\n",
    "import math\n",
    "import numpy\n",
    "import string\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "dictionary = collections.defaultdict(list)\n",
    "\n",
    "idf_dict = {}\n",
    "\n",
    "FILE_NAME = 'estadao_noticias_eleicao.csv'\n",
    "\n",
    "df = pd.read_csv(FILE_NAME)\n",
    "df = df.replace(numpy.NAN, \"\")\n",
    "\n",
    "# criação de uma nova coluna para a junção do título da notícia com seu conteúdo\n",
    "df['noticia'] = df.titulo + ' ' + df.subTitulo + ' ' + df.conteudo\n",
    "\n",
    "total_docs = len(df.noticia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Implementar funções auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pre_process_data(text):\n",
    "    return text.lower()\n",
    "\n",
    "def create_indexes(tokens, docId):\n",
    "    for word in tokens:\n",
    "        if word in dictionary: \n",
    "            if docId in dictionary[word]:\n",
    "                dictionary[word][docId] += 1 \n",
    "            else:\n",
    "                dictionary[word][docId] = 1 \n",
    "        else:\n",
    "            dictionary[word] = {}\n",
    "            dictionary[word][docId] = 1\n",
    "            \n",
    "def create_idf(word):\n",
    "    idf = calculate_idf(word)\n",
    "    idf_dict[word] = idf\n",
    "    \n",
    "def calculate_idf(word):\n",
    "    M = total_docs\n",
    "    k = len(dictionary[word].keys())\n",
    "    idf = math.log((M + 1) / k)\n",
    "    return idf\n",
    "\n",
    "def calculate_bm25(tf, k):\n",
    "    return (( k + 1) * tf) / ( tf + k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Criar índice invertido, calcular TF e IDF\n",
    "  A seguir criaremos o índice invertido, contendo cada palavra do dicionário, o número de vezes que essa palavra aparece em cada documento (chamado **TF** - *term frequency*) e um valor que tenta rankear as palavras de acordo com o número total de documentos e o número de documentos que contém cada palavra (chamado **IDF** - *inverse document frequency*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():  \n",
    "    tokens = nltk.word_tokenize(pre_process_data(row.noticia)) \n",
    "    create_indexes(tokens, row.idNoticia)\n",
    "for word in dictionary:\n",
    "    create_idf(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Modelos Vetoriais\n",
    "### 2.1 Representação binária\n",
    "Este modelo se assemelha a uma busca booleana AND, que leva em consideração apenas a ocorrência ou não dos termos nos documentos, e retorna os documentos que contém todos os termos da consulta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def binary_representation(query):\n",
    "    query = query.lower().split(' ')\n",
    "    intersect_dict = {}\n",
    "    aux = {}\n",
    "\n",
    "    for docId in dictionary[query[0]]:\n",
    "        aux[docId] = 1\n",
    "    \n",
    "    for word in query[1:]:   \n",
    "        for docId in dictionary[word]:\n",
    "            if docId in aux:\n",
    "                intersect_dict[docId] = 1\n",
    "        \n",
    "    rank = [(k, intersect_dict[k]) for k in sorted(intersect_dict, key=intersect_dict.get, reverse=True)]\n",
    "\n",
    "    return [doc[0] for doc in rank[:5]] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Term Frequency\n",
    "Esse modelo é um pouco melhor que a representação binária, pois leva em consideração o número de vezes que a palavra ocorre nos documentos, retornando assim os documentos que contém todos os termos da busca e que mais aparecem também."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tf(query):\n",
    "    query = query.lower().split(' ')\n",
    "    intersect_dict = {}\n",
    "    aux = {}\n",
    "\n",
    "    for docId in dictionary[query[0]]:\n",
    "        aux[docId] = dictionary[query[0]][docId]\n",
    "    \n",
    "    for word in query[1:]:   \n",
    "        for docId in dictionary[word]:\n",
    "            if docId in aux:\n",
    "                intersect_dict[docId] = aux[docId] + dictionary[word][docId]\n",
    "        \n",
    "    rank = [(k, intersect_dict[k]) for k in sorted(intersect_dict, key=intersect_dict.get, reverse=True)]\n",
    "\n",
    "    return [doc[0] for doc in rank[:5]]       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 TF-IDF\n",
    "O modelo TF-IDF leva em consideração a proporção de frequência dos termos em todo os documentos, a fim de penalizar os termos mais populares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tf_idf(query):\n",
    "    query = query.lower().split(' ')\n",
    "    intersect_dict = {}\n",
    "    aux = {}\n",
    "\n",
    "    for docId in dictionary[query[0]]:\n",
    "        aux[docId] = dictionary[query[0]][docId] * idf_dict[query[0]]\n",
    "    \n",
    "    for word in query[1:]:   \n",
    "        for docId in dictionary[word]:\n",
    "            if docId in aux:\n",
    "                intersect_dict[docId] = aux[docId] + (dictionary[word][docId] * idf_dict[word])\n",
    "        \n",
    "    rank = [(k, intersect_dict[k]) for k in sorted(intersect_dict, key=intersect_dict.get, reverse=True)]\n",
    "\n",
    "    return [doc[0] for doc in rank[:5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 BM25\n",
    "O modelo BM25 considera a relevância do termo baseado no TF e em um número k arbitrário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bm25(query, k):\n",
    "    query = query.lower().split(' ')\n",
    "    intersect_dict = {}\n",
    "    aux = {}\n",
    "\n",
    "    for docId in dictionary[query[0]]:\n",
    "        aux[docId] = calculate_bm25(dictionary[query[0]][docId], k) * idf_dict[query[0]]\n",
    "    \n",
    "    for word in query[1:]:   \n",
    "        for docId in dictionary[word]:\n",
    "            if docId in aux:\n",
    "                intersect_dict[docId] = aux[docId] + (calculate_bm25(dictionary[query[0]][docId], k) * idf_dict[word])\n",
    "        \n",
    "    rank = [(i, intersect_dict[i]) for i in sorted(intersect_dict, key=intersect_dict.get, reverse=True)]\n",
    "\n",
    "    return [doc[0] for doc in rank[:5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Validando os modelos\n",
    "Para validação, utilizaremos o MAP (*Mean Average Precision*) para comparar a eficiência dos modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Executando  consultas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GABARITO_FILE_NAME = 'gabarito.csv'\n",
    "gabarito = pd.read_csv(GABARITO_FILE_NAME)\n",
    "\n",
    "queries = ['segundo turno', 'lava jato', 'projeto de lei', 'compra de voto', 'ministério público']\n",
    "binary_representation_results = []\n",
    "tf_results = []\n",
    "tf_idf_results = []\n",
    "bm25_results = []\n",
    "\n",
    "for query in queries:\n",
    "    binary_representation_results.append(binary_representation(query))\n",
    "    tf_results.append(tf(query))\n",
    "    tf_idf_results.append(tf_idf(query))\n",
    "    bm25_results.append(bm25(query, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def apk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the average precision at k.\n",
    "\n",
    "    This function computes the average prescision at k between two lists of\n",
    "    items.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of elements that are to be predicted (order doesn't matter)\n",
    "    predicted : list\n",
    "                A list of predicted elements (order does matter)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The average precision at k over the input lists\n",
    "\n",
    "    \"\"\"\n",
    "    if len(predicted)>k:\n",
    "        predicted = predicted[:k]\n",
    "\n",
    "    score = 0.0\n",
    "    num_hits = 0.0\n",
    "\n",
    "    for i,p in enumerate(predicted):\n",
    "        if p in actual and p not in predicted[:i]:\n",
    "            num_hits += 1.0\n",
    "            score += num_hits / (i+1.0)\n",
    "\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "def mapk(actual, predicted, k=10):\n",
    "    \"\"\"\n",
    "    Computes the mean average precision at k.\n",
    "\n",
    "    This function computes the mean average prescision at k between two lists\n",
    "    of lists of items.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    actual : list\n",
    "             A list of lists of elements that are to be predicted \n",
    "             (order doesn't matter in the lists)\n",
    "    predicted : list\n",
    "                A list of lists of predicted elements\n",
    "                (order matters in the lists)\n",
    "    k : int, optional\n",
    "        The maximum number of predicted elements\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "            The mean average precision at k over the input lists\n",
    "\n",
    "    \"\"\"\n",
    "    return numpy.mean([apk(a,p,k) for a,p in zip(actual, predicted)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado MAP de acordo com o gabarito\n",
      "Precisão gabarito e busca binária: 0.240000\n",
      "Precisão gabarito e TF: 0.592000\n",
      "Precisão gabarito e TF-IDF: 0.748667\n",
      "Precisão gabarito e BM25: 0.780667 \n",
      "\n",
      "Resultado MAP de acordo com o google\n",
      "Precisão google e busca binária: 0.013333\n",
      "Precisão google e TF: 0.088000\n",
      "Precisão google e TF-IDF: 0.088000\n",
      "Precisão google e BM25: 0.073333\n"
     ]
    }
   ],
   "source": [
    "def obj_to_list(obj):\n",
    "    matrix = []\n",
    "    for list_obj in obj:\n",
    "        x = ast.literal_eval(list_obj)\n",
    "        matrix.append(x)\n",
    "    return matrix \n",
    "\n",
    "print('Resultado MAP de acordo com o gabarito')\n",
    "\n",
    "print (\"Precisão gabarito e busca binária: %f\" % (mapk(obj_to_list(gabarito.busca_binaria), binary_representation_results, k=5)))\n",
    "print (\"Precisão gabarito e TF: %f\" % (mapk(obj_to_list(gabarito.tf), tf_idf_results, k=5)))\n",
    "print (\"Precisão gabarito e TF-IDF: %f\" % (mapk(obj_to_list(gabarito.tfidf), tf_idf_results, k=5)))\n",
    "print (\"Precisão gabarito e BM25: %f \\n\" % (mapk(obj_to_list(gabarito.bm25), bm25_results, k=5)))\n",
    "\n",
    "print('Resultado MAP de acordo com o google')\n",
    "\n",
    "print (\"Precisão google e busca binária: %f\" % (mapk(obj_to_list(gabarito.google), binary_representation_results, k=5)))\n",
    "print (\"Precisão google e TF: %f\" % (mapk(obj_to_list(gabarito.google), tf_idf_results, k=5)))\n",
    "print (\"Precisão google e TF-IDF: %f\" % (mapk(obj_to_list(gabarito.google), tf_idf_results, k=5)))\n",
    "print (\"Precisão google e BM25: %f\" % (mapk(obj_to_list(gabarito.google), bm25_results, k=5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "   Como se pode observar acima, os modelos tiveram resultados bem diversos mas dentro do esperado. Se sabe que entre os modelos implementados, a **representação binária** é a mais ruim, por causa da aleatoriedade na hora de retornar os 5 melhores documentos, uma vez que todos eles possuem score igual a 1 e desta forma fica difícil retornar os mesmos elementos que o gabarito. O **TF** obteve um resultado melhor que a representação binária, pois como já foi tido anteriormente, ele leva em conta a frequência dos termos da busca e desta forma fica mais fácil fazer o ranking. Este modelo também possui limitações, pois quando a palavra é comum (por exemplo: a, para, de) o score aumenta bastante mas nem sempre os documentos retornados estarão no ranking ideal. O **TF-IDF** tenta minimizar este problema levando em consideração o IDF também, penalizando os termos mais comuns e gratificanto os termos mais raros dos documentos, tornando a recuperação mais relevante e por isso obteve melhor nota que os anteriores. O último e mais bem avaliado modelo é o **BM25**, que leva em conta o IDF, o TF e um parâmetro k arbitrário, que junto ao TF penaliza os termos que ocorrem muitas vezes em um documento e retorna os documentos mais relevantes que os demais, por levar vários aspectos em consideração na hora de calcular os scores e fazer o ranking."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
